import os
import time
import numpy as np
from typing import Optional, Dict
from plyfile import PlyData, PlyElement
from scipy.spatial.transform import Rotation as R
import torch
import numpy as np
from plyfile import PlyData
from gsplat.rendering import rasterization
from torchvision.utils import save_image
import math
import os
import time
from typing import Optional, Dict, Union

def gaussian_splatting_merge(
        base_scene_ply: Optional[str],
        new_asset_ply: str,
        position: Dict[str, float],
        rotation: Dict[str, float],
        scale: Optional[Dict[str, float]] = None,
        step: int = 0,
        output_dir: str = "tmp"
) -> str:
    """
    å°†æ–°çš„é«˜æ–¯æ¨¡å‹èµ„äº§åˆå¹¶åˆ°åŸºç¡€åœºæ™¯ä¸­ã€‚

    Args:
        base_scene_ply: åŸºç¡€åœºæ™¯çš„PLYæ–‡ä»¶è·¯å¾„ã€‚å¦‚æœä¸ºNoneï¼Œåˆ™åªå¯¹æ–°èµ„äº§è¿›è¡Œå˜æ¢ã€‚
        new_asset_ply: è¦æ·»åŠ çš„æ–°èµ„äº§PLYæ–‡ä»¶è·¯å¾„ã€‚
        position: ä½ç½®å­—å…¸ï¼Œæ ¼å¼: {'x': 0.0, 'y': 0.0, 'z': 0.0}
        rotation: æ—‹è½¬å­—å…¸ï¼ˆæ¬§æ‹‰è§’ï¼Œå•ä½ï¼šåº¦ï¼‰ï¼Œæ ¼å¼: {'x': 0.0, 'y': 0.0, 'z': 0.0}
        scale: ç¼©æ”¾å­—å…¸ï¼Œæ ¼å¼: {'x': 1.0, 'y': 1.0, 'z': 1.0}ã€‚é»˜è®¤ä¸ºNoneï¼ˆæ— ç¼©æ”¾ï¼‰
        step: æ­¥éª¤ç¼–å·ï¼Œç”¨äºç”Ÿæˆè¾“å‡ºæ–‡ä»¶åã€‚
        output_dir: è¾“å‡ºç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸º "tmp"

    Returns:
        str: åˆå¹¶åçš„PLYæ–‡ä»¶è·¯å¾„ã€‚

    Example:
        >>> merged = gaussian_splatting_merge(
        ...     base_scene_ply="scene.ply",
        ...     new_asset_ply="building.ply",
        ...     position={'x': 0, 'y': 0.5, 'z': 0.3},
        ...     rotation={'x': 0, 'y': 0, 'z': 90},
        ...     scale={'x': 1.2, 'y': 1.2, 'z': 1.0},
        ...     step=1
        ... )
    """

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)

    # è½¬æ¢å­—å…¸å‚æ•°ä¸ºnumpyæ•°ç»„
    pos_array = np.array([position.get('x', 0),
                          position.get('y', 0),
                          position.get('z', 0)], dtype=np.float32)

    rot_array = [rotation.get('x', 0),
                 rotation.get('y', 0),
                 rotation.get('z', 0)]

    # å¤„ç†ç¼©æ”¾å‚æ•°ï¼ˆå¦‚æœæœªæä¾›åˆ™é»˜è®¤ä¸º1ï¼‰
    if scale is None:
        scale_array = np.array([1.0, 1.0, 1.0], dtype=np.float32)
    else:
        scale_array = np.array([scale.get('x', 1.0),
                                scale.get('y', 1.0),
                                scale.get('z', 1.0)], dtype=np.float32)

    print(f"\n[Gaussian Splatting Merge] Step {step}")
    print(f"  ğŸ“¦ New asset: {new_asset_ply}")
    print(f"  ğŸ“ Position: {pos_array}")
    print(f"  ğŸ”„ Rotation: {rot_array}Â°")
    print(f"  ğŸ“ Scale: {scale_array}")

    all_vertices_data = []
    vertex_dtype = None

    try:
        # 1. å¦‚æœå­˜åœ¨åŸºç¡€åœºæ™¯ï¼Œå…ˆåŠ è½½å®ƒ
        if base_scene_ply and os.path.exists(base_scene_ply):
            print(f"  â³ Loading base scene: {base_scene_ply}")
            base_ply = PlyData.read(base_scene_ply)
            base_vertices = base_ply['vertex']
            all_vertices_data.append(base_vertices.data)
            vertex_dtype = base_vertices.data.dtype
            print(f"     âœ“ Base scene loaded: {len(base_vertices.data)} vertices")

        # 2. åŠ è½½æ–°èµ„äº§
        if not os.path.exists(new_asset_ply):
            raise FileNotFoundError(f"Asset file not found: {new_asset_ply}")

        print(f"  â³ Loading new asset: {new_asset_ply}")
        asset_ply = PlyData.read(new_asset_ply)
        asset_vertices = asset_ply['vertex']

        # å¦‚æœè¿™æ˜¯ç¬¬ä¸€ä¸ªåŠ è½½çš„æ–‡ä»¶ï¼Œè®°å½•æ•°æ®ç»“æ„
        if vertex_dtype is None:
            vertex_dtype = asset_vertices.data.dtype

        # 3. æå–é¡¶ç‚¹åæ ‡
        points = np.vstack([
            asset_vertices['x'],
            asset_vertices['y'],
            asset_vertices['z']
        ]).T

        print(f"     âœ“ Asset loaded: {len(points)} vertices")

        # 4. åº”ç”¨å˜æ¢ï¼ˆç¼©æ”¾ -> æ—‹è½¬ -> å¹³ç§»ï¼‰
        print(f"  ğŸ”§ Applying transformations...")

        # a. ç¼©æ”¾
        if not np.allclose(scale_array, [1.0, 1.0, 1.0]):
            points = points * scale_array
            print(f"     âœ“ Scaled by {scale_array}")

        # b. æ—‹è½¬
        if any(r != 0 for r in rot_array):
            rotation_matrix = R.from_euler('xyz', rot_array, degrees=True).as_matrix()
            points = points @ rotation_matrix.T
            print(f"     âœ“ Rotated by {rot_array}Â°")

        # c. å¹³ç§»
        if not np.allclose(pos_array, [0, 0, 0]):
            points = points + pos_array
            print(f"     âœ“ Translated by {pos_array}")

        # 5. æ›´æ–°å˜æ¢åçš„é¡¶ç‚¹æ•°æ®
        transformed_data = np.copy(asset_vertices.data)
        transformed_data['x'] = points[:, 0]
        transformed_data['y'] = points[:, 1]
        transformed_data['z'] = points[:, 2]

        all_vertices_data.append(transformed_data)

        # 6. åˆå¹¶æ‰€æœ‰é¡¶ç‚¹
        print(f"  ğŸ”— Merging vertices...")
        final_vertices = np.concatenate(all_vertices_data)
        print(f"     âœ“ Total vertices: {len(final_vertices)}")

        # 7. åˆ›å»ºå¹¶ä¿å­˜PLYæ–‡ä»¶
        output_filename = f"scene_merged_step_{step}.ply"
        output_path = os.path.join(output_dir, output_filename)

        final_element = PlyElement.describe(final_vertices, 'vertex')
        final_ply = PlyData([final_element])

        print(f"  ğŸ’¾ Saving to: {output_path}")
        final_ply.write(output_path)
        print(f"  âœ… Merge completed successfully!\n")

        return output_path

    except Exception as e:
        print(f"  âŒ Error during merge: {e}")
        raise

# =================================================================================
#  load_ply å‡½æ•° (æ— éœ€ä¿®æ”¹)
# =================================================================================
def load_ply(path, device="cuda"):
    plydata = PlyData.read(path)
    vertices = plydata['vertex']
    points = np.vstack([vertices['x'], vertices['y'], vertices['z']]).T
    opacities = torch.sigmoid(torch.tensor(vertices['opacity'], dtype=torch.float32, device=device))
    scales = torch.exp(torch.tensor(np.vstack([
        vertices['scale_0'], vertices['scale_1'], vertices['scale_2']
    ]), dtype=torch.float32, device=device).T)
    rotations = torch.tensor(np.vstack([
        vertices['rot_0'], vertices['rot_1'], vertices['rot_2'], vertices['rot_3']
    ]), dtype=torch.float32, device=device).T
    C0 = 0.28209479177387814
    rgbs = np.vstack([vertices['f_dc_0'], vertices['f_dc_1'], vertices['f_dc_2']]).T
    rgbs = C0 * rgbs + 0.5
    rgbs = np.clip(rgbs, 0.0, 1.0)
    return (
        torch.tensor(points, dtype=torch.float32, device=device),
        scales,
        torch.nn.functional.normalize(rotations),
        torch.tensor(rgbs, dtype=torch.float32, device=device),
        opacities.unsqueeze(-1),
    )


# =================================================================================
#  æ ¡æ­£æ¨¡å‹æ–¹å‘çš„å‡½æ•° (ä¿ç•™å¤‡ç”¨)
# =================================================================================
def correct_model_orientation(means, scales, quats):
    """ä¿ç•™æ­¤å‡½æ•°ä»¥å¤‡åç”¨"""
    device = means.device
    angle = -math.pi / 2
    cos_a, sin_a = math.cos(angle), math.sin(angle)
    correction_matrix_3x3 = torch.tensor([
        [1, 0, 0],
        [0, cos_a, sin_a],
        [0, -sin_a, cos_a]
    ], dtype=torch.float32, device=device)
    angle_half = angle / 2.0
    correction_quat = torch.tensor(
        [math.cos(angle_half), math.sin(angle_half), 0, 0],
        dtype=torch.float32, device=device
    )
    means_corrected = (means @ correction_matrix_3x3.T).float()
    qw_c, qx_c, qy_c, qz_c = correction_quat.unbind()
    qw, qx, qy, qz = quats.unbind(dim=-1)
    quats_corrected = torch.stack([
        qw_c * qw - qx_c * qx - qy_c * qy - qz_c * qz,
        qw_c * qx + qx_c * qw + qy_c * qz - qz_c * qy,
        qw_c * qy - qx_c * qz + qy_c * qw + qz_c * qx,
        qw_c * qz + qx_c * qy - qy_c * qx + qz_c * qw,
    ], dim=-1).float()
    print("æ¨¡å‹åæ ‡å·²æ ¡æ­£ï¼šç»•Xè½´æ—‹è½¬-90åº¦ã€‚")
    return means_corrected, scales, quats_corrected


# =================================================================================
#  render_view å‡½æ•°
# =================================================================================
def render_view(
        means, scales, quats, rgbs, opacities,
        width, height,
        elevation_deg, azimuth_deg,
        output_path
):
    device = means.device
    scene_center = means.mean(dim=0)
    scene_size = torch.max(torch.sqrt(torch.sum((means - scene_center) ** 2, dim=1))).item()
    camera_distance = scene_size * 2.5
    elevation = math.radians(elevation_deg)
    azimuth = math.radians(azimuth_deg)
    x_offset = camera_distance * math.cos(elevation) * math.sin(azimuth)
    y_offset = camera_distance * math.sin(elevation)
    z_offset = camera_distance * math.cos(elevation) * math.cos(azimuth)
    camera_pos = scene_center + torch.tensor([x_offset, y_offset, z_offset], device=device, dtype=torch.float32)
    look_at = scene_center

    if abs(elevation_deg - 90.0) < 1e-3:
        up_vector = torch.tensor([0.0, 0.0, -1.0], device=device, dtype=torch.float32)
    elif abs(elevation_deg + 90.0) < 1e-3:
        up_vector = torch.tensor([0.0, 0.0, 1.0], device=device, dtype=torch.float32)
    else:
        up_vector = torch.tensor([0.0, 1.0, 0.0], device=device, dtype=torch.float32)

    forward_dir = torch.nn.functional.normalize(look_at - camera_pos, dim=-1)
    right_dir = torch.nn.functional.normalize(torch.cross(forward_dir, up_vector), dim=-1)
    up_dir = torch.nn.functional.normalize(torch.cross(right_dir, forward_dir), dim=-1)
    c2w = torch.eye(4, device=device, dtype=torch.float32)
    c2w[:3, 0], c2w[:3, 1], c2w[:3, 2], c2w[:3, 3] = right_dir, up_dir, forward_dir, camera_pos
    world_to_view = torch.linalg.inv(c2w).unsqueeze(0)
    fovy = math.radians(49.1)
    fy = height / (2 * math.tan(fovy / 2))
    fx = fy
    K = torch.tensor([[fx, 0, width / 2], [0, fy, height / 2], [0, 0, 1]], device=device,
                     dtype=torch.float32).unsqueeze(0)
    backgrounds = torch.ones(3, device=device, dtype=torch.float32)

    print(f"   - æ­£åœ¨æ¸²æŸ“è§†è§’ (ä»°è§’={elevation_deg}Â°, æ–¹ä½è§’={azimuth_deg}Â°)...")

    outputs, _, _ = rasterization(
        means=means.float(),
        quats=quats.float(),
        scales=scales.float(),
        opacities=opacities.squeeze(-1).float(),
        colors=rgbs.float(),
        viewmats=world_to_view.float(),
        Ks=K.float(),
        height=height,
        width=width,
        render_mode='RGB',
        backgrounds=backgrounds.float()
    )

    save_image(outputs[0].permute(2, 0, 1), output_path)
    print(f"   - å›¾åƒå·²ä¿å­˜åˆ° '{output_path}'")
    return output_path


# =================================================================================
#  å°è£…çš„é«˜æ–¯æ¸²æŸ“å¿«ç…§å‡½æ•°
# =================================================================================
def gaussian_splatting_snapshot(
        scene_ply: Optional[str],
        camera_mode: str,
        info: str,
        target_pos: Optional[Dict] = None,
        width: int = 1024,
        height: int = 1024,
        apply_correction: bool = False,
        output_dir: str = "tmp"
) -> Dict[str, str]:
    """
    ã€å·²å‡çº§ã€‘ä¸ºé«˜æ–¯åœºæ™¯ç”Ÿæˆå¿«ç…§ã€‚

    å‚æ•°:
        scene_ply: .plyæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸ºNoneåˆ™è¿”å›ç©ºç»“æœ
        camera_mode: ç›¸æœºæ¨¡å¼ï¼Œå¯é€‰ "all"(å…¨éƒ¨è§†è§’), "front", "top", "left", "perspective"
        info: ç”¨äºæ–‡ä»¶å‘½åçš„æ ‡è¯†ä¿¡æ¯
        target_pos: å¯é€‰çš„ç›®æ ‡ä½ç½®å­—å…¸ï¼ˆé¢„ç•™å‚æ•°ï¼Œæš‚æœªä½¿ç”¨ï¼‰
        width: æ¸²æŸ“å®½åº¦
        height: æ¸²æŸ“é«˜åº¦
        apply_correction: æ˜¯å¦åº”ç”¨åæ ‡æ ¡æ­£
        output_dir: è¾“å‡ºç›®å½•

    è¿”å›:
        Dict[str, str]: è§†è§’åç§°åˆ°å›¾ç‰‡è·¯å¾„çš„æ˜ å°„
            ä¾‹å¦‚: {"front": "tmp/snapshot_info_front.png", "top": "tmp/snapshot_info_top.png", ...}
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    # å¦‚æœæ²¡æœ‰æä¾›åœºæ™¯æ–‡ä»¶ï¼Œè¿”å›ç©ºç»“æœ
    if scene_ply is None:
        scene_name = "empty_scene"
        print(f"   - [WARNING] æœªæä¾›åœºæ™¯æ–‡ä»¶ï¼Œæ— æ³•ç”Ÿæˆå¿«ç…§")
        return {}

    scene_name = os.path.basename(scene_ply)
    print(f"   - [Gaussian Splatting] æ­£åœ¨ä¸ºåœºæ™¯ '{scene_name}' ç”Ÿæˆ '{camera_mode}' å¿«ç…§ (info: '{info}')...")

    # è®¾å¤‡é€‰æ‹©
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"   - ä½¿ç”¨è®¾å¤‡: {device}")

    # åŠ è½½PLYæ–‡ä»¶
    try:
        (means, scales, quats, rgbs, opacities) = load_ply(scene_ply, device=device)
        print(f"   - æˆåŠŸåŠ è½½ {means.shape[0]} ä¸ªé«˜æ–¯çƒ")
    except Exception as e:
        print(f"   - [ERROR] åŠ è½½ .ply æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return {}

    # åº”ç”¨åæ ‡æ ¡æ­£ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if apply_correction:
        means, scales, quats = correct_model_orientation(means, scales, quats)

    # æ‰“å°ç‰©ä½“å°ºå¯¸ä¿¡æ¯
    min_coords, _ = torch.min(means, dim=0)
    max_coords, _ = torch.max(means, dim=0)
    dimensions = max_coords - min_coords
    print(
        f"   - ç‰©ä½“å°ºå¯¸ (X/Y/Z): {dimensions[0].item():.3f} / {dimensions[1].item():.3f} / {dimensions[2].item():.3f}")

    # å®šä¹‰è§†è§’é…ç½®
    all_views = {
        "front": {"elevation": 0, "azimuth": 180},
        "top": {"elevation": -90, "azimuth": 0},
        "left": {"elevation": 0, "azimuth": 270},
        "perspective": {"elevation": -150, "azimuth": 45},
    }

    # æ ¹æ®camera_modeé€‰æ‹©è¦æ¸²æŸ“çš„è§†è§’
    if camera_mode.lower() == "all":
        views_to_render = all_views
    elif camera_mode.lower() in all_views:
        views_to_render = {camera_mode.lower(): all_views[camera_mode.lower()]}
    else:
        print(f"   - [WARNING] æœªçŸ¥çš„ç›¸æœºæ¨¡å¼ '{camera_mode}'ï¼Œå°†æ¸²æŸ“æ‰€æœ‰è§†è§’")
        views_to_render = all_views

    # æ¸²æŸ“å„ä¸ªè§†è§’
    snapshot_paths = {}
    for view_name, angles in views_to_render.items():
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        output_filename = f"snapshot_{info}_{view_name}.png"
        output_path = os.path.join(output_dir, output_filename)

        # æ¸²æŸ“è§†è§’
        try:
            rendered_path = render_view(
                means, scales, quats, rgbs, opacities,
                width, height,
                angles["elevation"], angles["azimuth"],
                output_path
            )
            snapshot_paths[view_name] = rendered_path
        except Exception as e:
            print(f"   - [ERROR] æ¸²æŸ“ '{view_name}' è§†è§’æ—¶å‡ºé”™: {e}")

    print(f"   - [å®Œæˆ] æˆåŠŸç”Ÿæˆ {len(snapshot_paths)} ä¸ªå¿«ç…§")
    return snapshot_paths


# =================================================================================
#  å‘åå…¼å®¹çš„ç”Ÿæˆå‡½æ•°
# =================================================================================
def generate_views(
        ply_path: str = "test.ply",
        base_output_path: str = "output.png",
        width: int = 1024,
        height: int = 768,
        apply_correction: bool = False
):
    """å‘åå…¼å®¹çš„ç”Ÿæˆå‡½æ•°"""
    path_without_ext, ext = os.path.splitext(base_output_path)
    output_dir = os.path.dirname(base_output_path) or "."
    info = os.path.basename(path_without_ext)

    snapshot_paths = gaussian_splatting_snapshot(
        scene_ply=ply_path,
        camera_mode="all",
        info=info,
        width=width,
        height=height,
        apply_correction=apply_correction,
        output_dir=output_dir
    )

    return snapshot_paths


if __name__ == "__main__":
    # ç¤ºä¾‹1: ä½¿ç”¨æ–°çš„å°è£…å‡½æ•°ï¼ˆæ¨èï¼‰
    snapshot_paths = gaussian_splatting_snapshot(
        scene_ply=r"D:\github\BuildingAgent\model_api\generated_model_2fac3c83\gaussian_f1ef57b4.ply",
        camera_mode="all",  # å¯é€‰: "all", "front", "top", "left", "perspective"
        info="test_render",
        width=1024,
        height=1024,
        apply_correction=False,
        output_dir="tmp"
    )

    print("\nç”Ÿæˆçš„å¿«ç…§è·¯å¾„:")
    for view_name, path in snapshot_paths.items():
        print(f"  {view_name}: {path}")

    # ç¤ºä¾‹1: ä½¿ç”¨çœŸå®å‡½æ•°
    print("=" * 60)
    print("ç¤ºä¾‹ 1: çœŸå®PLYåˆå¹¶")
    print("=" * 60)

    try:
        merged_scene = gaussian_splatting_merge(
            base_scene_ply=None,  # ç¬¬ä¸€ä¸ªç‰©ä½“ï¼Œæ— åŸºç¡€åœºæ™¯
            new_asset_ply="test3.ply",
            position={'x': 0, 'y': 0.4865, 'z': 0.2986},
            rotation={'x': 0, 'y': 0, 'z': 0},
            scale={'x': 1.0, 'y': 1.0, 'z': 1.0},
            step=1
        )

        # æ·»åŠ ç¬¬äºŒä¸ªç‰©ä½“
        merged_scene = gaussian_splatting_merge(
            base_scene_ply=merged_scene,  # ä½¿ç”¨ä¸Šä¸€æ­¥çš„ç»“æœ
            new_asset_ply="test4.ply",
            position={'x': 0, 'y': -0.4327, 'z': 0.21115},
            rotation={'x': 0, 'y': 0, 'z': 90},
            scale={'x': 1.2, 'y': 1.2, 'z': 1.0},  # ç¼©æ”¾1.2å€
            step=2
        )

        # æ·»åŠ ç¬¬ä¸‰ä¸ªç‰©ä½“
        merged_scene = gaussian_splatting_merge(
            base_scene_ply=merged_scene,
            new_asset_ply="test5.ply",
            position={'x': 0, 'y': 0, 'z': 0},
            rotation={'x': 0, 'y': 0, 'z': 0},
            scale={'x': 0.8, 'y': 0.8, 'z': 1.5},  # è‡ªå®šä¹‰ç¼©æ”¾
            step=3
        )

        print(f"\nğŸ‰ æœ€ç»ˆåœºæ™¯: {merged_scene}")

    except Exception as e:
        print(f"\nâš ï¸  çœŸå®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡çœŸå®æµ‹è¯•: {e}")

